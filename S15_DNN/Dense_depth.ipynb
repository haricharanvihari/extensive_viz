{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dense_depth.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haricharanvihari/extensive_viz/blob/master/S15_DNN/Dense_depth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_1g7LrKWsES",
        "colab_type": "text"
      },
      "source": [
        "# **Depth Model creation**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68M_mY_bKQzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "77d8810f-cd6c-4888-e7c3-50fc4f6f8d35"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBqqg8EjW0fk",
        "colab_type": "text"
      },
      "source": [
        "## **Clone the repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMDfsePtLun_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d3d7accd-cb61-4867-a911-a656ce32e954"
      },
      "source": [
        "!git clone https://github.com/Sushmitha-Katti/DepthModel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DepthModel'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 245 (delta 124), reused 244 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (245/245), 11.81 MiB | 25.96 MiB/s, done.\n",
            "Resolving deltas: 100% (124/124), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Scv-fHZW5V0",
        "colab_type": "text"
      },
      "source": [
        "**Load Pre trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSBnlTmiNzoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "4acb9484-495e-4c87-9265-ffcf47d06189"
      },
      "source": [
        "#load pretrained model\n",
        "!wget https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5 -O ./DepthModel/nyu.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-18 05:33:20--  https://s3-eu-west-1.amazonaws.com/densedepth/nyu.h5\n",
            "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.218.106.51\n",
            "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.218.106.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 172897376 (165M) [application/h5]\n",
            "Saving to: ‘./DepthModel/nyu.h5’\n",
            "\n",
            "./DepthModel/nyu.h5 100%[===================>] 164.89M  10.7MB/s    in 17s     \n",
            "\n",
            "2020-07-18 05:33:38 (9.54 MB/s) - ‘./DepthModel/nyu.h5’ saved [172897376/172897376]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jixtFt2jW-f1",
        "colab_type": "text"
      },
      "source": [
        "## **Extract the fg-bg images from zip**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL3zMBfoN2Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract only fg-bg-images from zip file\n",
        "import zipfile\n",
        "\n",
        "archive = zipfile.ZipFile('/content/gdrive/My Drive/EVA/S15/maskrcnndataset_overlay.zip')\n",
        "\n",
        "#for file in archive.namelist():\n",
        "archive.extractall('/content/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAItMoN5OJ8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75420858-ee8b-4633-c234-8ac47d346083"
      },
      "source": [
        "! ls '/content/maskrcnndataset_overlay/' | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "392041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkK7VvMXJ0-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3c426fec-3d2b-476f-e22e-fa74a8bdd29b"
      },
      "source": [
        "# !ls '/content/gdrive/My Drive/EVA/S15/maskrcnndataset/bgfg_depth' | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot open directory '/content/gdrive/My Drive/mask_rcnn_dataset/bgfg_depth3': Input/output error\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__5C1v3SXUh9",
        "colab_type": "text"
      },
      "source": [
        "## **Should be in DepthModel path**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NPQauEsagRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1532f4f5-7a1c-421a-fdc9-d554c93612ab"
      },
      "source": [
        "%cd DepthModel\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DepthModel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmfL-KrYXZQB",
        "colab_type": "text"
      },
      "source": [
        "## **Modified utils.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8mDgt4ShGzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utils.py from the depth model\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import notebook\n",
        "\n",
        "def DepthNorm(x, maxDepth):\n",
        "    return maxDepth / x\n",
        "\n",
        "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
        "    # Support multiple RGBs, one RGB image, even grayscale \n",
        "    if len(images.shape) < 3: images = np.stack((images,images,images), axis=2)\n",
        "    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\n",
        "    # Compute predictions\n",
        "    predictions = model.predict(images, batch_size=batch_size)\n",
        "    # Put in expected range\n",
        "    return np.clip(DepthNorm(predictions, maxDepth=1000), minDepth, maxDepth) / maxDepth\n",
        "\n",
        "def scale_up(scale, images):\n",
        "    from skimage.transform import resize\n",
        "    scaled = []\n",
        "    \n",
        "    for i in range(len(images)):\n",
        "        img = images[i]\n",
        "        output_shape = (scale * img.shape[0], scale * img.shape[1])\n",
        "        scaled.append( resize(img, output_shape, order=1, preserve_range=True, mode='reflect', anti_aliasing=True ) )\n",
        "\n",
        "    return np.stack(scaled)\n",
        "\n",
        "def load_images(image_files):\n",
        "    loaded_images = []\n",
        "    for file in image_files:\n",
        "        x = np.clip(np.asarray(Image.open( file ), dtype=float) / 255, 0, 1)\n",
        "        loaded_images.append(x)\n",
        "    return np.stack(loaded_images, axis=0)\n",
        "\n",
        "def to_multichannel(i):\n",
        "    if i.shape[2] == 3: return i\n",
        "    i = i[:,:,0]\n",
        "    return np.stack((i,i,i), axis=2)\n",
        "\n",
        "def display_images(filename, output_path, outputs, inputs=None, gt=None, is_colormap=True, is_rescale=True):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import skimage\n",
        "    from skimage.transform import resize\n",
        "\n",
        "    plasma = plt.get_cmap('gray')\n",
        "    #shape = (outputs[0].shape[0], outputs[0].shape[1], 3)\n",
        "    \n",
        "    for i in range(outputs.shape[0]):\n",
        "        imgs = []\n",
        "        \n",
        "        rescaled = outputs[i][:,:,0]\n",
        "        if is_rescale:\n",
        "            rescaled = rescaled - np.min(rescaled)\n",
        "            rescaled = rescaled / np.max(rescaled)\n",
        "        matplotlib_image = plt.imshow(plasma(rescaled)[:,:,:3])\n",
        "\n",
        "        pil_image = Image.fromarray(np.uint8( ( matplotlib_image.get_array()*255))).convert(\"L\").resize((224,224))\n",
        "        pil_image.save(os.path.join(output_path, \"depth_\" + filename + \".jpg\"))\n",
        "        plt.close()\n",
        "        \n",
        "    return True\n",
        "\n",
        "def save_images(filename, outputs, inputs=None, gt=None, is_colormap=True, is_rescale=False):\n",
        "    montage =  display_images(outputs, inputs, is_colormap, is_rescale)\n",
        "    im = Image.fromarray(np.uint8(montage*255))\n",
        "    im.save(filename)\n",
        "\n",
        "def load_test_data(test_data_zip_file='nyu_test.zip'):\n",
        "    print('Loading test data...', end='')\n",
        "    import numpy as np\n",
        "    from data import extract_zip\n",
        "    data = extract_zip(test_data_zip_file)\n",
        "    from io import BytesIO\n",
        "    rgb = np.load(BytesIO(data['eigen_test_rgb.npy']))\n",
        "    depth = np.load(BytesIO(data['eigen_test_depth.npy']))\n",
        "    crop = np.load(BytesIO(data['eigen_test_crop.npy']))\n",
        "    print('Test data loaded.\\n')\n",
        "    return {'rgb':rgb, 'depth':depth, 'crop':crop}\n",
        "\n",
        "def evaluate(model, rgb, depth, crop, batch_size=6, verbose=True):\n",
        "    # Error computaiton based on https://github.com/tinghuiz/SfMLearner\n",
        "    def compute_errors(gt, pred):\n",
        "        thresh = np.maximum((gt / pred), (pred / gt))\n",
        "        \n",
        "        a1 = (thresh < 1.25   ).mean()\n",
        "        a2 = (thresh < 1.25 ** 2).mean()\n",
        "        a3 = (thresh < 1.25 ** 3).mean()\n",
        "\n",
        "        abs_rel = np.mean(np.abs(gt - pred) / gt)\n",
        "\n",
        "        rmse = (gt - pred) ** 2\n",
        "        rmse = np.sqrt(rmse.mean())\n",
        "\n",
        "        log_10 = (np.abs(np.log10(gt)-np.log10(pred))).mean()\n",
        "\n",
        "        return a1, a2, a3, abs_rel, rmse, log_10\n",
        "\n",
        "    depth_scores = np.zeros((6, len(rgb))) # six metrics\n",
        "\n",
        "    bs = batch_size\n",
        "\n",
        "    for i in range(len(rgb)//bs):    \n",
        "        x = rgb[(i)*bs:(i+1)*bs,:,:,:]\n",
        "        \n",
        "        # Compute results\n",
        "        true_y = depth[(i)*bs:(i+1)*bs,:,:]\n",
        "        pred_y = scale_up(2, predict(model, x/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "        \n",
        "        # Test time augmentation: mirror image estimate\n",
        "        pred_y_flip = scale_up(2, predict(model, x[...,::-1,:]/255, minDepth=10, maxDepth=1000, batch_size=bs)[:,:,:,0]) * 10.0\n",
        "\n",
        "        # Crop based on Eigen et al. crop\n",
        "        true_y = true_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y = pred_y[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        pred_y_flip = pred_y_flip[:,crop[0]:crop[1]+1, crop[2]:crop[3]+1]\n",
        "        \n",
        "        # Compute errors per image in batch\n",
        "        for j in range(len(true_y)):\n",
        "            errors = compute_errors(true_y[j], (0.5 * pred_y[j]) + (0.5 * np.fliplr(pred_y_flip[j])))\n",
        "            \n",
        "            for k in range(len(errors)):\n",
        "                depth_scores[k][(i*bs)+j] = errors[k]\n",
        "\n",
        "    e = depth_scores.mean(axis=1)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"{:>10}, {:>10}, {:>10}, {:>10}, {:>10}, {:>10}\".format('a1', 'a2', 'a3', 'rel', 'rms', 'log_10'))\n",
        "        print(\"{:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}, {:10.4f}\".format(e[0],e[1],e[2],e[3],e[4],e[5]))\n",
        "\n",
        "    return e\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaM4f46FXfd8",
        "colab_type": "text"
      },
      "source": [
        "## **Modified test.py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0kw0Qn3fGWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b008a57-2166-4c6d-bef5-9161cecfd82b"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import argparse\n",
        "import time\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import PIL\n",
        "import gc\n",
        "\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Kerasa / TensorFlow\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '5'\n",
        "from keras.models import load_model\n",
        "from layers import BilinearUpSampling2D\n",
        "from loss import depth_loss_function\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Argument Parser\n",
        "#parser = argparse.ArgumentParser(description='High Quality Monocular Depth Estimation via Transfer Learning')\n",
        "#parser.add_argument('--model', default='nyu.h5', type=str, help='Trained Keras model file.')\n",
        "#parser.add_argument('--input', default='my_examples', type=str, help='Input filename or folder.')\n",
        "#parser.add_argument('--image_output', default='my_out_examples', type=str, help='Output filename or folder.')\n",
        "#args = parser.parse_args()\n",
        "\n",
        "iteration = 6\n",
        "\n",
        "args = {\"model\": \"nyu.h5\",\n",
        "        \"input\": \"/content/maskrcnndataset_overlay/\",\n",
        "        \"output\": \"/content/bgfg_depth\" + str(iteration) + \"/\"}\n",
        "\n",
        "# Custom object needed for inference and training\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "\n",
        "# Load model into GPU / CPU\n",
        "def load_images_with_resize(image_files):\n",
        "    loaded_images = []\n",
        "    for file in image_files:\n",
        "        with Image.open( file ) as im:\n",
        "            im = im.resize((640, 480), PIL.Image.ANTIALIAS)\n",
        "            x = np.clip(np.asarray(im, dtype=float) / 255, 0, 1)\n",
        "            loaded_images.append(x)\n",
        "    return np.stack(loaded_images, axis=0)\n",
        "\n",
        "def process_depth_estimate(model, input_folder, output_folder, file_pattern):\n",
        "  custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': depth_loss_function}\n",
        "  print('Loading model...')\n",
        "  model = load_model(model, custom_objects=custom_objects, compile=False)\n",
        "  end = time.time()\n",
        "  print('\\nModel loaded ({0}) in time {1}.'.format(args[\"model\"], end - start))\n",
        "\n",
        "  pbar = tqdm(enumerate(glob.glob(input_folder + file_pattern)))\n",
        "  for pidx, input_image in pbar:\n",
        "    a = input_image.split('/')\n",
        "    filename = a[len(a) - 1]\n",
        "\n",
        "    pbar.set_description(\"Processing image: \" + filename)\n",
        "                         \n",
        "    temp = filename.split('.')\n",
        "    filename_w_ext = temp[0]\n",
        "    # Input images\n",
        "    with Image.open( input_image ) as im:\n",
        "        im = im.resize((640, 480), PIL.Image.ANTIALIAS)\n",
        "        x = np.clip(np.asarray(im, dtype=float) / 255, 0, 1)\n",
        "    inputs = np.stack([x], axis=0)\n",
        "\n",
        "    # Compute results\n",
        "    outputs = predict(model, inputs)\n",
        "    # Display results\n",
        "    plasma = plt.get_cmap('gray')\n",
        "    output_copy = outputs.copy()\n",
        "    for i in range(output_copy.shape[0]):\n",
        "        imgs = []\n",
        "        \n",
        "        rescaled = output_copy[i][:,:,0]\n",
        "        rescaled = rescaled - np.min(rescaled)\n",
        "        rescaled = rescaled / np.max(rescaled)\n",
        "        matplotlib_image = plt.imshow(plasma(rescaled)[:,:,:3])\n",
        "\n",
        "        pil_image = Image.fromarray(np.uint8( ( matplotlib_image.get_array()*255))).convert(\"L\").resize((224,224))\n",
        "        pil_image.save(os.path.join(output_folder, \"depth_\" + filename_w_ext + \".jpg\"))\n",
        "        plt.close()\n",
        "        \n",
        "    del inputs\n",
        "    del outputs\n",
        "    del output_copy\n",
        "    del matplotlib_image\n",
        "\n",
        "    if pidx == 1 or pidx % 400 == 0:\n",
        "        gc.collect()\n",
        "  del pbar\n",
        "\n",
        "result_list = []\n",
        "def log_result(result):\n",
        "    # This is called whenever foo_pool(i) returns a result.\n",
        "    # result_list is modified only by the main process, not the pool workers.\n",
        "    result_list.append(result)\n",
        "\n",
        "for k in range(iteration * 10, (iteration + 1) * 10):\n",
        "    p = mp.Pool(processes =1)\n",
        "    if k < 38:\n",
        "        continue\n",
        "    file_pattern1 = \"ol_bg0\" + str(k) + \"*.png\"\n",
        "    #result = process_depth_estimate(args[\"model\"], args[\"input\"], args[\"output\"], file_pattern1)\n",
        "    print(\"Working on images: \", file_pattern1)\n",
        "    result = p.apply_async(process_depth_estimate, args = (args[\"model\"], args[\"input\"], args[\"output\"], file_pattern1), callback = log_result)\n",
        "    p.close()\n",
        "    p.join()\n",
        "    end = time.time()\n",
        "    print('Done. It took: ', end - start)\n",
        "    print('\\n')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading model...\n",
            "Working on images:  ol_bg060*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 12.661651134490967.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg060fg01818_fg_018.png: : 3960it [30:13,  2.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  1826.8447065353394\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg061*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 1839.3499157428741.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg061fg0576_fg_057.png: : 3960it [29:50,  2.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  3630.681072950363\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg062*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 3643.115250349045.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg062fg02912f_fg_029.png: : 3960it [29:58,  2.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  5442.456272125244\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg063*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 5455.064640283585.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg063fg06715_fg_067.png: : 3960it [29:47,  2.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  7243.322902441025\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg064*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 7255.839416742325.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg064fg0848f_fg_084.png: : 3960it [29:52,  2.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  9048.911547660828\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg065*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 9061.612252235413.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg065fg0456_fg_045.png: : 3960it [30:23,  2.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  10886.322452545166\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg066*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 10898.497171640396.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg066fg08515f_fg_085.png: : 3960it [30:44,  2.15it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  12743.569900989532\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg067*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 12756.129028558731.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg067fg08519_fg_085.png: : 3960it [30:55,  2.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  14613.56743311882\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg068*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 14625.981585502625.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg068fg08916_fg_089.png: : 3960it [30:26,  2.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. It took:  16453.332018375397\n",
            "\n",
            "\n",
            "Loading model...\n",
            "Working on images:  ol_bg069*.png\n",
            "\n",
            "Model loaded (nyu.h5) in time 16466.14886546135.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing image: ol_bg069fg08610_fg_086.png: : 3537it [27:18,  2.22it/s] "
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12V3zGwR1Qzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC_oDTQtMIwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm -rf /content/bgfg_output/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS8rFht891Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !ls Depth_Part1/ | wc -l #count of images after crashing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh3AR7TLSLXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5WV35gsXmcw",
        "colab_type": "text"
      },
      "source": [
        "## **Zip and save in drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qNaAMLb-IoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#zip the images and save it in drive\n",
        "\n",
        "from zipfile import ZipFile \n",
        "import os \n",
        "  \n",
        "def get_all_file_paths(directory): \n",
        "  \n",
        "    # initializing empty file paths list \n",
        "    file_paths = [] \n",
        "  \n",
        "    # crawling through directory and subdirectories \n",
        "    for root, directories, files in os.walk(directory): \n",
        "        for filename in files: \n",
        "            # join the two strings in order to form the full filepath. \n",
        "            filepath = os.path.join(root, filename) \n",
        "            file_paths.append(filepath) \n",
        "  \n",
        "    # returning all file paths \n",
        "    return file_paths         \n",
        "  \n",
        "def main(zip_file_name, input_dir, output_dir): \n",
        "    # calling function to get all file paths in the directory \n",
        "    file_paths = get_all_file_paths(input_dir) \n",
        "  \n",
        "    # printing the list of all files to be zipped \n",
        "    print('Following files will be zipped:') \n",
        "    print(file_paths) \n",
        "  \n",
        "    # writing files to a zipfile \n",
        "    with ZipFile(os.path.join(output_dir, zip_file_name),'a') as zip: \n",
        "        # writing each file one by one \n",
        "        for file in file_paths: \n",
        "            zip.write(file) \n",
        "  \n",
        "    print('All files zipped successfully!')         \n",
        "\n",
        "zip_file_name = \"bgfg_depth\" + str(iteration)\n",
        "input_folder = \"/content/bgfg_depth\" + str(iteration) + \"/\"\n",
        "output_folder = \"/content/bgfg_depth_zip/\"\n",
        "\n",
        "main(zip_file_name, input_folder, output_folder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AGjV3eQYbqy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0776b831-6203-4e0e-fceb-2ba1da2cce1f"
      },
      "source": [
        "!ls '/content/gdrive/My Drive/mask_rcnn_dataset/bgfg_depth_zip' -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 121965\n",
            "-rw------- 1 root root 124891574 Jul 18 10:21 bgfg_depth5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eP6qJnuncxsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "52d5e909-0c81-4510-98b8-882e169d08cc"
      },
      "source": [
        "!du -sh /content/gdrive/'My Drive'/mask_rcnn_dataset/bgfg_depth_zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120M\t/content/gdrive/My Drive/mask_rcnn_dataset/bgfg_depth_zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBDK6iG6Xt4W",
        "colab_type": "text"
      },
      "source": [
        "## **Sample depth image for the fg-bg image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkfstNfvZ7vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "Image.open(\"/content/bgfg_output/depth_ol_bg001fg0011_fg_001.png.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxtUokM8aMWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "Image.open(\"/content/bgfg_output/depth_ol_bg001fg0011_fg_001.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}